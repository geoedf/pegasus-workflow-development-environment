{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diamond Workflow\n",
    "\n",
    "This notebook will generate the **diamond workflow** illustrated below, then plan and execute the workflow on the local condorpool. Rectangles represent input/output files, and ovals represent compute jobs. The arrows represent file dependencies between each compute job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg viewBox=\"0.00 0.00 734.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><g class=\"graph\" id=\"graph1\" transform=\"scale(1 1) rotate(0) translate(4 94)\"><title>G</title><polygon fill=\"white\" points=\"-4,5 -4,-94 731,-94 731,5 -4,5\" stroke=\"white\"/><!-- f.a --><g class=\"node\" id=\"node2\"><title>f.a</title><polygon fill=\"none\" points=\"54,-63 0,-63 0,-27 54,-27 54,-63\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"27\" y=\"-40.8\">f.a</text></g><!-- preprocess --><g class=\"node\" id=\"node9\"><title>preprocess</title><ellipse cx=\"143\" cy=\"-45\" fill=\"none\" rx=\"52.1463\" ry=\"18\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-40.8\">preprocess</text></g><!-- f.a&#45;&gt;preprocess --><g class=\"edge\" id=\"edge3\"><title>f.a-&gt;preprocess</title><path d=\"M54.1539,-45C62.071,-45 71.1241,-45 80.3409,-45\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"80.3602,-48.5001 90.3602,-45 80.3601,-41.5001 80.3602,-48.5001\" stroke=\"black\"/></g><!-- f.b1 --><g class=\"node\" id=\"node3\"><title>f.b1</title><polygon fill=\"none\" points=\"286,-90 232,-90 232,-54 286,-54 286,-90\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-67.8\">f.b1</text></g><!-- findrange1 --><g class=\"node\" id=\"node13\"><title>findrange1</title><ellipse cx=\"375\" cy=\"-72\" fill=\"none\" rx=\"52.7315\" ry=\"18\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-67.8\">findrange1</text></g><!-- f.b1&#45;&gt;findrange1 --><g class=\"edge\" id=\"edge9\"><title>f.b1-&gt;findrange1</title><path d=\"M286.154,-72C293.891,-72 302.714,-72 311.713,-72\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"311.901,-75.5001 321.901,-72 311.901,-68.5001 311.901,-75.5001\" stroke=\"black\"/></g><!-- f.b2 --><g class=\"node\" id=\"node4\"><title>f.b2</title><polygon fill=\"none\" points=\"286,-36 232,-36 232,0 286,0 286,-36\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-13.8\">f.b2</text></g><!-- findrange2 --><g class=\"node\" id=\"node15\"><title>findrange2</title><ellipse cx=\"375\" cy=\"-18\" fill=\"none\" rx=\"52.7315\" ry=\"18\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-13.8\">findrange2</text></g><!-- f.b2&#45;&gt;findrange2 --><g class=\"edge\" id=\"edge11\"><title>f.b2-&gt;findrange2</title><path d=\"M286.154,-18C293.891,-18 302.714,-18 311.713,-18\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"311.901,-21.5001 321.901,-18 311.901,-14.5001 311.901,-21.5001\" stroke=\"black\"/></g><!-- f.c1 --><g class=\"node\" id=\"node5\"><title>f.c1</title><polygon fill=\"none\" points=\"518,-90 464,-90 464,-54 518,-54 518,-90\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491\" y=\"-67.8\">f.c1</text></g><!-- analyze --><g class=\"node\" id=\"node19\"><title>analyze</title><ellipse cx=\"595\" cy=\"-45\" fill=\"none\" rx=\"40.548\" ry=\"18\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"595\" y=\"-40.8\">analyze</text></g><!-- f.c1&#45;&gt;analyze --><g class=\"edge\" id=\"edge17\"><title>f.c1-&gt;analyze</title><path d=\"M518.003,-65.1169C527.673,-62.557 538.937,-59.5754 549.784,-56.7042\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"550.799,-60.0561 559.571,-54.1136 549.008,-53.2891 550.799,-60.0561\" stroke=\"black\"/></g><!-- f.c2 --><g class=\"node\" id=\"node6\"><title>f.c2</title><polygon fill=\"none\" points=\"518,-36 464,-36 464,0 518,0 518,-36\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491\" y=\"-13.8\">f.c2</text></g><!-- f.c2&#45;&gt;analyze --><g class=\"edge\" id=\"edge19\"><title>f.c2-&gt;analyze</title><path d=\"M518.003,-24.8831C527.673,-27.443 538.937,-30.4246 549.784,-33.2958\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"549.008,-36.7109 559.571,-35.8864 550.799,-29.9439 549.008,-36.7109\" stroke=\"black\"/></g><!-- f.d --><g class=\"node\" id=\"node7\"><title>f.d</title><polygon fill=\"none\" points=\"726,-63 672,-63 672,-27 726,-27 726,-63\" stroke=\"black\"/><text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699\" y=\"-40.8\">f.d</text></g><!-- preprocess&#45;&gt;f.b1 --><g class=\"edge\" id=\"edge5\"><title>preprocess-&gt;f.b1</title><path d=\"M186.449,-55.0538C198.082,-57.8088 210.58,-60.769 221.825,-63.4323\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"221.201,-66.8813 231.739,-65.7802 222.815,-60.0697 221.201,-66.8813\" stroke=\"black\"/></g><!-- preprocess&#45;&gt;f.b2 --><g class=\"edge\" id=\"edge7\"><title>preprocess-&gt;f.b2</title><path d=\"M186.449,-34.9462C198.082,-32.1912 210.58,-29.231 221.825,-26.5677\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"222.815,-29.9303 231.739,-24.2198 221.201,-23.1187 222.815,-29.9303\" stroke=\"black\"/></g><!-- findrange1&#45;&gt;f.c1 --><g class=\"edge\" id=\"edge13\"><title>findrange1-&gt;f.c1</title><path d=\"M427.996,-72C436.749,-72 445.661,-72 453.898,-72\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"453.906,-75.5001 463.906,-72 453.906,-68.5001 453.906,-75.5001\" stroke=\"black\"/></g><!-- findrange2&#45;&gt;f.c2 --><g class=\"edge\" id=\"edge15\"><title>findrange2-&gt;f.c2</title><path d=\"M427.996,-18C436.749,-18 445.661,-18 453.898,-18\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"453.906,-21.5001 463.906,-18 453.906,-14.5001 453.906,-21.5001\" stroke=\"black\"/></g><!-- analyze&#45;&gt;f.d --><g class=\"edge\" id=\"edge21\"><title>analyze-&gt;f.d</title><path d=\"M635.728,-45C644.223,-45 653.158,-45 661.524,-45\" fill=\"none\" stroke=\"black\"/><polygon fill=\"black\" points=\"661.741,-48.5001 671.741,-45 661.741,-41.5001 661.741,-48.5001\" stroke=\"black\"/></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import SVG\n",
    "SVG(filename='diamond.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Python API\n",
    "\n",
    "Import required packages. <br>\n",
    "```\n",
    "from Pegasus.api.mixins import EventType, Namespace\n",
    "from Pegasus.api.properties import Properties\n",
    "from Pegasus.api.replica_catalog import File, ReplicaCatalog\n",
    "from Pegasus.api.site_catalog import (\n",
    "    OS,\n",
    "    Arch,\n",
    "    Directory,\n",
    "    FileServer,\n",
    "    Grid,\n",
    "    Operation,\n",
    "    Scheduler,\n",
    "    Site,\n",
    "    SiteCatalog,\n",
    ")\n",
    "from Pegasus.api.transformation_catalog import (\n",
    "    Container,\n",
    "    Transformation,\n",
    "    TransformationCatalog,\n",
    "    TransformationSite,\n",
    ")\n",
    "from Pegasus.api.workflow import Job, SubWorkflow, Workflow\n",
    "from Pegasus.client._client import PegasusClientError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from Pegasus.api import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Logging\n",
    "\n",
    "Configure logging. While this is **not required**, it is useful for seeing output from tools such as `pegasus-plan`, `pegasus-analyzer`, etc. when using these python wrappers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Pegasus Properties\n",
    "\n",
    "The `pegasus.properties` file can now be generated using the `Properties()` object as shown below. To see a list of the most commonly used properties, you can use `Properties.ls(prefix)`. By default, `pegasus-plan` will look in `cwd` for a `pegasus.properties` file if one is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condor.request_cpus\n",
      "condor.request_disk\n",
      "condor.request_gpus\n",
      "condor.request_memory\n"
     ]
    }
   ],
   "source": [
    "Properties.ls(\"condor.request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Properties ---------------------------------------------------------------\n",
    "props = Properties()\n",
    "props[\"pegasus.monitord.encoding\"] = \"json\"                                                                    \n",
    "props[\"pegasus.catalog.workflow.amqp.url\"] = \"amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows\"\n",
    "props.write() # written to ./pegasus.properties "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Replica Catalog (Specify Initial Input Files)\n",
    "\n",
    "Any initial input files given to the workflow should be specified in the `ReplicaCatalog`. This object tells Pegasus where each input file is physically located. First, we create a file that will be used as input to this workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"f.a\", \"w\") as f:\n",
    "    f.write(\"This is the contents of the input file for the diamond workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `./f.a` will be used in this workflow, and so we create a corresponding `File` object. Metadata may also be added to the file as shown below.\n",
    "\n",
    "Next, a `ReplicaCatalog` object is created so that the physical locations of each input file can be cataloged. This is done using the `ReplicaCatalog.add_replica(site, file, path)` function. As the file `f.a` resides here on the submit machine, we use the reserved keyword `local` for the site parameter. Second, the `File` object is passed in for the `file` parameter. Finally, the absolute path to the file is given. `pathlib.Path` may be used as long as an absolute path is given. \n",
    "\n",
    "By default, `pegasus-plan` will look in `cwd` for a `replicas.yml` file if one is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Replicas -----------------------------------------------------------------\n",
    "fa = File(\"f.a\").add_metadata(creator=\"ryan\")\n",
    "rc = ReplicaCatalog()\\\n",
    "    .add_replica(\"local\", fa, Path(\".\").resolve() / \"f.a\")\\\n",
    "    .write() # written to ./replicas.yml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Transformation Catalog (Specify Executables Used)\n",
    "\n",
    "Any executable (referred to as ***transformations***) used by the workflow needs to be specified in the `TransformationCatalog`. This is done by creating `Transformation` objects, which represent executables. Once created, these must be added to the `TransformationCatalog` object. \n",
    "\n",
    "By default, `pegasus-plan` will look in `cwd` for a `transformations.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transformations ----------------------------------------------------------\n",
    "preprocess = Transformation(\n",
    "                \"preprocess\",\n",
    "                site=\"condorpool\",\n",
    "                pfn=\"/home/scitech/pegasus/dist/pegasus/bin/pegasus-keg\",\n",
    "                is_stageable=False,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            )\n",
    "\n",
    "findrange = Transformation(\n",
    "                \"findrange\",\n",
    "                site=\"condorpool\",\n",
    "                pfn=\"/home/scitech/pegasus/dist/pegasus/bin/pegasus-keg\",\n",
    "                is_stageable=False,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            )\n",
    "\n",
    "analyze = Transformation(\n",
    "                \"analyze\",\n",
    "                site=\"condorpool\",\n",
    "                pfn=\"/home/scitech/pegasus/dist/pegasus/bin/pegasus-keg\",\n",
    "                is_stageable=False,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            )\n",
    "\n",
    "tc = TransformationCatalog()\\\n",
    "    .add_transformations(preprocess, findrange, analyze)\\\n",
    "    .write() # ./written to ./transformations.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the Workflow\n",
    "\n",
    "The `Workflow` object is used to store jobs and dependencies between each job. Typical job creation is as follows:\n",
    "\n",
    "```\n",
    "# Define job Input/Output files\n",
    "input_file = File(\"input.txt\")\n",
    "output_file1 = File(\"output1.txt\")\n",
    "output_file2 = File(\"output2.txt\")\n",
    "\n",
    "# Define job, passing in the transformation (executable) it will use\n",
    "j = Job(transformation_obj)\n",
    "\n",
    "# Specify command line arguments (if any) which will be passed to the transformation when run\n",
    "j.add_args(\"arg1\", \"arg2\", input_file, \"arg3\", output_file)\n",
    "\n",
    "# Specify input files (if any)\n",
    "j.add_inputs(input_file)\n",
    "\n",
    "# Specify output files (if any)\n",
    "j.add_outputs(output_file1, output_file2)\n",
    "\n",
    "# Add profiles to the job\n",
    "j.add_env(FOO=\"bar\")\n",
    "j.add_profiles(Namespace.PEGASUS, key=\"checkpoint.time\", value=1)\n",
    "\n",
    "# Add the job to the workflow object\n",
    "wf.add_jobs(j)\n",
    "```\n",
    "\n",
    "By default, depedencies between jobs are inferred based on input and output files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Workflow at 0x7f7ca040ea20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Workflow -----------------------------------------------------------------\n",
    "wf = Workflow(\"blackdiamond\")\n",
    "\n",
    "fb1 = File(\"f.b1\")\n",
    "fb2 = File(\"f.b2\")\n",
    "job_preprocess = Job(preprocess)\\\n",
    "                    .add_args(\"-a\", \"preprocess\", \"-T\", \"3\", \"-i\", fa, \"-o\", fb1, fb2)\\\n",
    "                    .add_inputs(fa)\\\n",
    "                    .add_outputs(fb1, fb2)\n",
    "\n",
    "fc1 = File(\"f.c1\")\n",
    "job_findrange_1 = Job(findrange)\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb1, \"-o\", fc1)\\\n",
    "                    .add_inputs(fb1)\\\n",
    "                    .add_outputs(fc1)\n",
    "\n",
    "fc2 = File(\"f.c2\")\n",
    "job_findrange_2 = Job(findrange)\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb2, \"-o\", fc2)\\\n",
    "                    .add_inputs(fb2)\\\n",
    "                    .add_outputs(fc2)\n",
    "\n",
    "fd = File(\"f.d\")\n",
    "job_analyze = Job(analyze)\\\n",
    "                .add_args(\"-a\", \"analyze\", \"-T\", \"3\", \"-i\", fc1, fc2, \"-o\", fd)\\\n",
    "                .add_inputs(fc1, fc2)\\\n",
    "                .add_outputs(fd)\n",
    "\n",
    "wf.add_jobs(job_preprocess, job_findrange_1, job_findrange_2, job_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Workflow\n",
    "\n",
    "Using the reference do the `Workflow` object, you can plan, run, and monitor the workflow directly. These are wrappers around Pegasus CLI tools, and as such, the same arguments may be passed to them. \n",
    "\n",
    "**Note that the Pegasus binaries must be added to your PATH for this to work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "################\n",
      "# pegasus-plan #\n",
      "################\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword $defs - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword additionalItems - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword examples - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "2020.08.07 00:46:01.742 UTC:\n",
      "2020.08.07 00:46:01.747 UTC:   -----------------------------------------------------------------------\n",
      "2020.08.07 00:46:01.754 UTC:   File for submitting this DAG to HTCondor           : blackdiamond-0.dag.condor.sub\n",
      "2020.08.07 00:46:01.759 UTC:   Log of DAGMan debugging messages                 : blackdiamond-0.dag.dagman.out\n",
      "2020.08.07 00:46:01.765 UTC:   Log of HTCondor library output                     : blackdiamond-0.dag.lib.out\n",
      "2020.08.07 00:46:01.772 UTC:   Log of HTCondor library error messages             : blackdiamond-0.dag.lib.err\n",
      "2020.08.07 00:46:01.777 UTC:   Log of the life of condor_dagman itself          : blackdiamond-0.dag.dagman.log\n",
      "2020.08.07 00:46:01.783 UTC:\n",
      "2020.08.07 00:46:01.789 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with:\n",
      "2020.08.07 00:46:01.801 UTC:   -----------------------------------------------------------------------\n",
      "2020.08.07 00:46:02.683 UTC:   Your database is compatible with Pegasus version: 5.0.0beta1\n",
      "2020.08.07 00:46:03.820 UTC:   Created Pegasus database in: sqlite:////home/scitech/shared-data/sample-black-diamond-wf/scitech/pegasus/blackdiamond/run0001/blackdiamond-0.replicas.db\n",
      "2020.08.07 00:46:03.825 UTC:   Your database is compatible with Pegasus version: 5.0.0beta1\n",
      "2020.08.07 00:46:03.873 UTC:   Output replica catalog set to jdbc:sqlite:/home/scitech/shared-data/sample-black-diamond-wf/scitech/pegasus/blackdiamond/run0001/blackdiamond-0.replicas.db\n",
      "2020.08.07 00:46:04.038 UTC:   Submitting to condor blackdiamond-0.dag.condor.sub\n",
      "2020.08.07 00:46:04.066 UTC:\n",
      "2020.08.07 00:46:04.072 UTC:   Your workflow has been started and is running in the base directory:\n",
      "2020.08.07 00:46:04.078 UTC:\n",
      "2020.08.07 00:46:04.084 UTC:   /home/scitech/shared-data/sample-black-diamond-wf/scitech/pegasus/blackdiamond/run0001\n",
      "2020.08.07 00:46:04.090 UTC:\n",
      "2020.08.07 00:46:04.096 UTC:   *** To monitor the workflow you can run ***\n",
      "2020.08.07 00:46:04.101 UTC:\n",
      "2020.08.07 00:46:04.107 UTC:   pegasus-status -l /home/scitech/shared-data/sample-black-diamond-wf/scitech/pegasus/blackdiamond/run0001\n",
      "2020.08.07 00:46:04.113 UTC:\n",
      "2020.08.07 00:46:04.119 UTC:   *** To remove your workflow run ***\n",
      "2020.08.07 00:46:04.125 UTC:\n",
      "2020.08.07 00:46:04.131 UTC:   pegasus-remove /home/scitech/shared-data/sample-black-diamond-wf/scitech/pegasus/blackdiamond/run0001\n",
      "2020.08.07 00:46:05.118 UTC:   Time taken to execute is 4.428 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT  IN_STATE  JOB                                                                                                      \n",
      "Idle     00:01  blackdiamond-0 ( /home/scitech/shared-data/sample-black-diamond-wf/scitech/pegasus/blackdiamond/run0001 )\n",
      "Summary: 1 Condor job total (I:1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    wf.plan(submit=True)\\\n",
    "        .wait()\\\n",
    "        .analyze()\\\n",
    "        .statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
